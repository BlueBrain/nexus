{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YoCPKFu5lpwU"
   },
   "source": [
    "# A simple pipeline for recommending similar neuroscience datasets using knowledge graph node embeddings\n",
    "\n",
    "In this tutorial, you will:\n",
    "\n",
    "1. Select a Blue Brain Nexus project from which to search neuron morphology and electrophysiology recordings \n",
    "2. Prepare the metadata for knowledge graph embeddings\n",
    "3. Train a knowledge graph node embedding model and embed each neuron morphology\n",
    "4. Store and index the embeddings in Blue Brain Nexus\n",
    "5. Recommend similar neuron morphologies and electrophysiology recordings using the embeddings \n",
    "\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "This notebook makes use of a dataset made of mouse neuron morphologies downloaded from Allen Cell Types Database and MouseLight as well as mouse electrophysiology recordings from Allen Cell Types Database. This dataset is expected to be accessible from a Blue Brain Nexus Project to be configured below. If not, please run the `Tutorial: Integrate Neuroscience Datasets from Multiple Sources using MINDS` [notebook](https://github.com/BlueBrain/nexus/blob/master/docs/src/main/paradox/docs/getting-started/notebooks/dataset_from_different_sources.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyRDF2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nexusforge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install validators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Select a Blue Brain Nexus project from which to search neuron morphology and electrophysiology recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dFPUxxP7cWA"
   },
   "source": [
    "### Initialize and configure a client to access a Blue Brain Nexus Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get an authentication token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Nexus sandbox application](https://sandbox.bluebrainnexus.io/web) can be used to get a token:\n",
    "\n",
    "- Step 1: From the [web page](https://sandbox.bluebrainnexus.io/web), click on the login button in the top right corner and follow the instructions on screen.\n",
    "\n",
    "- Step 2: You will then see a `Copy token` button in the top right corner. Click on it to copy the token to the clipboard.\n",
    "\n",
    "Once a token is obtained, proceed to paste it as the value of the `TOKEN` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure a forge client to store, manage and access datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from kgforge.core import KnowledgeGraphForge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://raw.githubusercontent.com/BlueBrain/nexus/ef830192d4e7bb95f9351c4bdab7b0114c27e2f0/docs/src/main/paradox/docs/getting-started/notebooks/rdfmodel/jsonldcontext.json')\n",
    "dirpath = './rdfmodel'\n",
    "Path(dirpath).mkdir(parents=True, exist_ok=True)\n",
    "with open(f'{dirpath}/jsonldcontext.json', 'w') as outfile:\n",
    "    json.dump(r.json(), outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://sandbox.bluebrainnexus.io/v1\"\n",
    "ORG = \"github-users\"\n",
    "PROJECT = \"\"  # Provide here the automatically created project name created when you logged into the Nexus sandbox instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forge = KnowledgeGraphForge(\"https://raw.githubusercontent.com/BlueBrain/nexus/ef830192d4e7bb95f9351c4bdab7b0114c27e2f0/docs/src/main/paradox/docs/getting-started/notebooks/forge.yml\",\n",
    "                            bucket=f\"{ORG}/{PROJECT}\",\n",
    "                            endpoint=ENDPOINT,\n",
    "                            token=TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wwenZHtmlpwW"
   },
   "source": [
    "### Search neuron morphology and electrophysiolgy recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_to_display = [\"id\",\"type\",\"@id\",\"@type\",\"name\",\"subject\",\"brainLocation.brainRegion.id\",\"brainLocation.brainRegion.label\",\"brainLocation.layer.id\",\"brainLocation.layer.label\", \"contribution.agent.label\",\"brainLocation.layer.id\",\"brainLocation.layer.label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search neuron morphologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"NeuronMorphology\"\n",
    "\n",
    "filters = {\"type\": _type}\n",
    "\n",
    "number_of_results = 20\n",
    "\n",
    "morphologies = forge.search(filters, limit=number_of_results)\n",
    "\n",
    "print(f\"{str(len(morphologies))} dataset(s) of type {_type} found\")\n",
    "\n",
    "reshaped_data = forge.reshape(morphologies, keep = property_to_display)\n",
    "\n",
    "morphologies_df = forge.as_dataframe(reshaped_data)\n",
    "morphologies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search electrophysiolgy recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_type = \"Trace\"\n",
    "\n",
    "filters = {\"type\": _type}\n",
    "\n",
    "number_of_results = 20\n",
    "\n",
    "ephys = forge.search(filters, limit=number_of_results)\n",
    "\n",
    "print(f\"{str(len(ephys))} dataset(s) of type {_type} found\")\n",
    "\n",
    "reshaped_data = forge.reshape(ephys, keep = property_to_display)\n",
    "\n",
    "ephys_df = forge.as_dataframe(reshaped_data)\n",
    "ephys_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the metadata for knowledge graph embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, a clean graph data structure will be generated for the seraach results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ephys + morphologies\n",
    "graph = forge.as_graph(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrdf2vec.graphs import KG\n",
    "from pyrdf2vec.rdf2vec import KG as rdf2vecgraph\n",
    "from pyrdf2vec.graphs.vertex import Vertex\n",
    "import pyrdf2vec.rdf2vec\n",
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators\n",
    "\n",
    "def remove_bn_from_walk(walk):\n",
    "    new_walks= [item for index, item in enumerate(walk) if not (index!= 0 and validators.uuid(item)) and not str(item).startswith('N') and not str(item).startswith(\"b'\") and not str(item).startswith('b\"') and not str(item).startswith(\"ub\") and not str(item).startswith('t') and not str(item).startswith('rdflib.term.BNode') and '_' not in str(item)]\n",
    "    new_walks = tuple(new_walks)\n",
    "    return new_walks\n",
    "\n",
    "def keep_fragment(uri):\n",
    "    if str(uri).startswith('http') or str(uri).startswith('file'):\n",
    "        ns, fragment = rdflib.namespace.split_uri(str(uri).strip(\"/\").strip(\",\"))\n",
    "        return fragment\n",
    "    else:\n",
    "        return uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from rdflib.namespace import Namespace\n",
    "\n",
    "SCHEMAORG = Namespace('http://schema.org/')\n",
    "\n",
    "labels = {}\n",
    "kg = KG()\n",
    "def create_kg(kg, graph, label_predicates, source=\"\"):    \n",
    "    \n",
    "    for (s, p, o) in tqdm(graph.triples((None, None, None))):\n",
    "        if p == SCHEMAORG.name:\n",
    "            s_type = graph.objects(s, rdflib.namespace.RDF.type)\n",
    "            _type = \"\"\n",
    "            for t in s_type:\n",
    "                _type = _type+\"_\"+keep_fragment(str(t))\n",
    "            \n",
    "            labels[keep_fragment(str(s))] = _type+\"_\"+\"_\"+source+\"_\"+str(o)+\"_\"+keep_fragment(str(s))\n",
    "        if p not in label_predicates:    \n",
    "            s_v = Vertex(keep_fragment(str(s)))\n",
    "            o_v = Vertex(keep_fragment(str(o)))\n",
    "            p_v = Vertex(keep_fragment(str(p)), predicate=True, vprev=s_v, vnext=o_v)\n",
    "            kg.add_vertex(s_v)\n",
    "            kg.add_vertex(p_v)\n",
    "            kg.add_vertex(o_v)\n",
    "            kg.add_edge(s_v, p_v)\n",
    "            kg.add_edge(p_v, o_v)\n",
    "\n",
    "create_kg(kg, graph, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Neuron Morphologies and Electrophysiology recordings to build embeddings for\n",
    "\n",
    "entity_namespace = \"https://neuroshapes.org/\"\n",
    "\n",
    "type_ref = rdflib.term.URIRef(entity_namespace+\"NeuronMorphology\")\n",
    "graph_instances = [str(main_subject) for main_subject in graph.subjects(rdflib.namespace.RDF.type, type_ref)]\n",
    "type_ref_ephys = rdflib.term.URIRef(entity_namespace+\"Trace\")\n",
    "\n",
    "graph_instances.extend([str(main_subject) for main_subject in graph.subjects(rdflib.namespace.RDF.type, type_ref_ephys)])\n",
    "\n",
    "print(f\"{len(graph_instances)} Neuron Morphologies and Electrophysiology recordings instances found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Train a knowledge graph node embedding model and embed each neuron morphology and electrophysiology recordings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A knowledge graph embedding model represents each node (e.g. each Neuron Morphology or Electrophysiology Trace) in the graph with a numerical dense vector in a low dimension space with the aim that similar nodes will be close enough in that space. How close or similar two nodes are can be computed using a distance metric such as cosine similarity between their embedding vectors.\n",
    "\n",
    "For this tutorial, the [pyRDF2Vec](https://github.com/IBCNServices/pyRDF2Vec) will be used to generate embeddings for the selected Neuron Morphologies or Electrophysiology Traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "iLcrSdBINV1P",
    "outputId": "14310ff6-97b9-4ce0-ed91-686e559f770b"
   },
   "outputs": [],
   "source": [
    "from pyrdf2vec import RDF2VecTransformer\n",
    "from pyrdf2vec.walkers import RandomWalker, WLWalker, CommunityWalker, WalkletWalker, HALKWalker\n",
    "from pyrdf2vec.samplers import UniformSampler, PageRankSampler, ObjFreqSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walkers = [WLWalker(20, 100, ObjFreqSampler())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_to_text(graph,walkers, instances, unique=True):\n",
    "    walks_= []\n",
    "    for walker in walkers:\n",
    "            all_walks = list(walker.extract(graph, instances))\n",
    "           \n",
    "            walks_ += all_walks\n",
    "    print('Extracted {} walks for {} instances!'.format(len(walks_),\n",
    "                                                            len(instances)))\n",
    "    sentences = []\n",
    "    for x in walks_:\n",
    "        if x not in sentences:\n",
    "            sentences.append(list(map(str, remove_bn_from_walk(x))))\n",
    "        \n",
    "    unique_sentences = []\n",
    "    if unique:\n",
    "        \n",
    "        for s in sentences:\n",
    "            if s not in unique_sentences:\n",
    "                unique_sentences.append(s)\n",
    "    else:\n",
    "        unique_sentences = sentences\n",
    "\n",
    "    print(f\"Generated unique ({unique}) {len(sentences)} sentences without blank nodes\")\n",
    "    return sentences, walks_\n",
    "\n",
    "sentences, walks = graph_to_text(kg,walkers, graph_instances, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2Vec_transformer = RDF2VecTransformer(walkers=walkers)\n",
    "rdf2Vec_transformer.embedder.fit(sentences)\n",
    "rdf2Vec_transformer.embedder.transform(graph_instances)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = rdf2Vec_transformer.embedder.model_.wv.get_vector(\"https://bbp.epfl.ch/neurosciencegraph/data/neuronmorphologies/b79a7353-a853-4790-b319-c474aec3bd34\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def generate_tsne(model):\n",
    "    \"Creates and TSNE model and plots it\"\n",
    "\n",
    "    tokens = []\n",
    "    ls=[]\n",
    "\n",
    "    for word in model.wv.vocab:\n",
    "        if word in graph_instances:\n",
    "            tokens.append(model[word])\n",
    "            \n",
    "           \n",
    "            split_tables =labels[keep_fragment(word)].split(\"_\")\n",
    "            l = \"\".join(split_tables[0:5])\n",
    "            l = l.replace(\" \",\"_\")\n",
    "            ls.append(l)\n",
    "          \n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=3000, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(10, 10)) \n",
    "    for i in range(len(x)):\n",
    "        sc = plt.scatter(x[i],y[i], label=ls[i])\n",
    "        plt.annotate('',\n",
    "                     xy=(x[i], y[i]),\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "generate_tsne(rdf2Vec_transformer.embedder.model_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the embeddings vectors and metadata to disk and in the Nexus project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open(f\"vectors_rdf2vec_kg_embeddings.tsv\", 'w', encoding='utf-8')\n",
    "out_m = io.open(f\"metadata_rdf2vec_kg_embeddings.tsv\", 'w', encoding='utf-8')\n",
    "embeddings_matrix = []\n",
    "for entity in graph_instances:\n",
    "\n",
    "  entity_fragment = keep_fragment(entity)\n",
    "  entity_label=labels[keep_fragment(entity_fragment)]\n",
    "  embedding = transformer_origin.embedder.model_.wv.get_vector(str(entity))\n",
    "  \n",
    "  out_m.write(entity_label + \"\\n\")\n",
    "  out_v.write('\\t'.join([str(x) for x in embedding]) + \"\\n\")\n",
    "  entity_resource = forge.retrieve(id=entity)\n",
    "  entity_resource.embeddings = [float(x) for x in embedding]\n",
    "  forge.update(entity_resource)\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the embedding model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2Vec_transformer.embedder.model_.save(\"./kg_embedding_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Store and index the embeddings in Blue Brain Nexus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrde1uHplpxE"
   },
   "source": [
    "### Create an ElasticSearchView\n",
    "\n",
    "The goal here is to create an [Elasticsearch](https://www.elastic.co/elasticsearch/) index within the configured Nexus project in which to store and query the embeddings. Such index can be created using an [ElasticSearchView](https://bluebrainnexus.io/docs/delta/api/views/elasticsearch-view-api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nexussdk as nexus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G2lb5FejlpxH"
   },
   "outputs": [],
   "source": [
    "view_id=\"https://second_dataset_recommendatation_view\"\n",
    "type_to_index = [\"https://neuroshapes.org/NeuronMorphology\",\"https://neuroshapes.org/Trace\"]\n",
    "view_data = {\n",
    "    \"@type\": [\n",
    "        \"ElasticSearchView\"\n",
    "    ],\n",
    "    \"includeMetadata\": True,\n",
    "    \"includeDeprecated\": False,\n",
    "    \"resourceTypes\":type_to_index,\n",
    "    \"mapping\": {\n",
    "        \"properties\": {\n",
    "            \"@id\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"@type\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"embeddings\": {\n",
    "                \"type\":\"dense_vector\",\n",
    "                \"dims\":100\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"sourceAsText\": False\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = nexus.views.create_(org_label=ORG, project_label=PROJECT,payload=view_data,view_id=view_id)\n",
    "except nexus.HTTPError as ne:\n",
    "    print(ne.response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "## Recommend similar neuron morphologies and electrophysiology recordings using the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "#Configure forge to point to the newly created ElasticSearch view\n",
    "forge._store.service.elastic_endpoint[\"endpoint\"] = \"/\".join((ENDPOINT, \"views\", quote_plus(ORG), quote_plus(PROJECT), quote_plus(view_id), \"_search\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(item_id, q=\"*\", number_of_results=10, view_id=None):\n",
    "    \"\"\"\n",
    "    Given a movie id, execute the recommendation function score query to find similar movies, ranked by cosine similarity\n",
    "    \"\"\"\n",
    "    # Get the item from Nexus and retrieve its embedding\n",
    "    \n",
    "    item_source = forge.retrieve(id = item_id)\n",
    "    \n",
    "    # extract the embedding\n",
    "    item_embedding = item_source.embeddings\n",
    "    query = \"\"\"{\n",
    "\n",
    "          \"query\": {\n",
    "            \"script_score\": {\n",
    "              \"query\": {\n",
    "                    \"exists\": {\n",
    "                    \"field\": \"embeddings\"\n",
    "                    }\n",
    "              },\n",
    "              \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.queryVector, doc['embeddings'])+1.0\",\n",
    "                \"params\": {\n",
    "                  \"queryVector\": %s\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\"\"\" % (item_embedding)\n",
    "    results = forge.elastic(query=query, debug=False, limit=2)\n",
    "    scores = [r._score for r in results if hasattr(r, \"_score\")]\n",
    "    return [forge.from_json(dict(r._source)) for r in results if hasattr(r, \"_source\")], scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morphologies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a morphology id to recommend similar morphologies for.\n",
    "morphology_id = morphologies_df.id[0]\n",
    "morphology_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_results = 10\n",
    "forge._debug= True\n",
    "res, scores = get_similar_movies(item_id=morphology_id, \n",
    "                                 view_id=view_id,\n",
    "                                number_of_results=number_of_results)\n",
    "reshaped_res = forge.reshape(res, keep = property_to_display)\n",
    "#reshaped_res = [r]\n",
    "print(f\"Found {len(res)} Datasets\")\n",
    "result_df = forge.as_dataframe(reshaped_res)\n",
    "result_df.insert(0, \"score\", scores)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ephys_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an electrophysiology recording id to recommend similar electrophysiology recordings for.\n",
    "ephys_id = ephys_df.id[0]\n",
    "ephys_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_results = 10\n",
    "forge._debug= True\n",
    "res, scores = get_similar_movies(item_id=ephys_id, \n",
    "                                 view_id=view_id,\n",
    "                                number_of_results=number_of_results)\n",
    "reshaped_res = forge.reshape(res, keep = property_to_display)\n",
    "#reshaped_res = [r]\n",
    "print(f\"Found {len(res)} Datasets\")\n",
    "result_df = forge.as_dataframe(reshaped_res)\n",
    "result_df.insert(0, \"score\", scores)\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Building a Content-based Recommender System using Blue Brain Nexus.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (kgo)",
   "language": "python",
   "name": "kgo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
