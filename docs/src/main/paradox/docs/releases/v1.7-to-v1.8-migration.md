# v1.7 To v1.8 Migration

The v1.8 release of Delta introduces PostgreSQL as sole option for the Delta primary event store.

(To have a complete list of improvements, @ref:[see here](./v1.8-release-notes.md)).

These improvements require to replay all existing events, moving them from Cassandra to PostgreSql, and to reindex all
data to elasticsearch/Blazegraph.

The following steps describe how to perform the migration. At the end, Delta v1.8 will be running using PostgreSQL as
primary store.

Depending on the number and the complexity of existing resources and schemas in the system,
the migration may last several days (TODO: "insert event migration rate here") to complete.

## Requirements

* PostgreSQL 15.1 instance
* TODO: Storage/CPU/RAM recommendation.

## Prepare Cassandra

### Perform a backup

Perform a
@link:[backup](https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/operations/opsBackupRestore.html){
open=new } of the original keyspace `delta_1_5`
and perform a repair of the Cassandra nodes:

```cqlsh
nodetool repair
```

@@@ note { .warning }

We will assume from hereon that the existing Cassandra keyspace is `delta_1_5`.

@@@

### Create a materialized view on the messages table on the original keyspace

Create a materialized view on the messages table on the keyspace `delta_1_5`:

```sql
CREATE MATERIALIZED VIEW IF NOT EXISTS delta_1_5.ordered_messages AS
    SELECT ser_manifest, ser_id, event
    FROM delta_1_5.messages
    WHERE timebucket is not null
    AND persistence_id is not null
    AND partition_nr is not null
    AND sequence_nr is not null
    AND timestamp is not null
    PRIMARY KEY(timebucket, timestamp, persistence_id, partition_nr, sequence_nr)
    WITH CLUSTERING ORDER BY (timestamp asc);
```

The materialized view will take some time to build depending on the number of events.

### Check the materialized view

These operations may take a while to complete depending on the number of rows in the messages table.

* On the messages table:

```shell
cqlsh -e 'select timebucket from delta_1_5.messages' | grep rows
```

* On the materialized view:

```shell
cqlsh -e 'select timebucket from delta_1_5.ordered_messages' | grep rows
```

When the materialized view has the same number of rows as the table then it is ready for migration.

## Prepare PostgreSQL

### PostgreSQL requirements
TODO: Add PSQL requirements

### Create migration tables

Run the following command in the PostgreSQL instance to create the temporary tables needed for the migration:

```sql
CREATE TABLE IF NOT EXISTS public.migration_offset(
    name         text        NOT NULL,
    akka_offset  text        NOT NULL,
    processed    bigint      NOT NULL,
    discarded    bigint      NOT NULL,
    failed       bigint      NOT NULL,
    instant      timestamptz NOT NULL,
    PRIMARY KEY(name)
);

CREATE TABLE IF NOT EXISTS public.ignored_events(
    type            text        NOT NULL,
    persistence_id  text        NOT NULL,
    sequence_nr     bigint      NOT NULL,
    payload         JSONB       NOT NULL,
    instant         timestamptz NOT NULL,
    akka_offset     text        NOT NULL
);
```

## Migration configuration

### Pull the docker image for Delta 1.8

Pull the docker image for Delta 1.8 from @link:[Docker Hub](https://hub.docker.com/r/bluebrain/nexus-delta)

```shell
docker pull bluebrain/nexus-delta:1.8.x
```

### Configure Delta in migration mode

This section defines the mandatory configuration to run Delta in migration mode.

### Environment variables

The following environment variables need to be set when launching Delta v1.8 in migration mode:

* `KAMON_ENABLED`: false (not mandatory but recommended)
* `MIGRATE_DATA`: true
* `DISABLE_INDEXING`: true
* `MIGRATION_CONF`: /path/to/migration.conf
* `DELTA_PLUGINS`: /opt/docker/plugins/

### JVM parameters:

* Adopt the same values as the one for your current deployment

### Java properties

| Description                 | Property                                             | Example value                                                 |
|-----------------------------|------------------------------------------------------|---------------------------------------------------------------|
| PostgreSQL host             | app.defaults.database.host                           |                                                               |
| PostgreSQL username         | app.defaults.database.username                       |                                                               |
| PostgreSQL password         | app.defaults.database.password                       |                                                               |
| Service binding interface   | app.http.interface                                   | 0.0.0.0                                                       |
| Service Uri Path prefix     | app.http.base-uri                                    | {delta-url}:8080/v1                                           |
| Cassandra username          | datastax-java-driver.advanced.auth-provider.username |                                                               |
| Cassandra password          | datastax-java-driver.advanced.auth-provider.password |                                                               |
| Cassandra auth class        | datastax-java-driver.advanced.auth-provider.class    | PlainTextAuthProvider                                         |
| Cassandra contact point (1) | datastax-java-driver.basic.contact-points.0          | cassandra-1:9042                                              |
| Cassandra contact point (2) | datastax-java-driver.basic.contact-points.1          | cassandra-2:9042                                              |
| Cassandra timeout           | datastax-java-driver.basic.request.timeout           | 10 seconds                                                    |
| Cassandra pagination        | datastax-java-driver.basic.page-size                 | 500                                                           |
| Cassandra compression lib   | datastax-java-driver.advanced.protocol.compression   | lz4                                                           |
| Cassandra reconnect         | datastax-java-driver.advanced.reconnect-on-init      | true                                                          |
| Secrets encryption password | app.encryption.password                              |                                                               |
| Secrets encryption salt     | app.encryption.salt                                  |                                                               |
| Remote storage enabling     | plugins.storage.storages.remote-disk.enabled         | true/false                                                    |
| S3 storage enabling         | plugins.storage.storages.amazon.enabled              | true/false                                                    |
| Max interval                | migration.batch.max-interval                         | 1 minute                                                      |
| Max elements                | migration.batch.max-elements                         | 250                                                           |
| Delta cassandra keyspace    | migration.replay.keyspace                            | delta_1_5                                                     |
| Bucket size                 | migration.replay.bucket-size                         | "Hour"                                                        |
| Bucket of the first event   | migration.replay.first-time-bucket                   | YYYYMMDDTHH:MM (Same as the one on your Delta 1.7 deployment) |
| Refresh interval            | migration.replay.refresh-interval                    | 3s                                                            |
| Eventual consistency delay  | migration.replay.eventual-consistency-delay          | 30s                                                           |
| Queries buffer size         | migration.replay.max-buffer-size                     | 250                                                           |
| Projects to ignore          | migration.ignore.blacklist                           | [ "org/proj" ], []                                            |

**TODO** Add info on PSQL pool size config?

## Migrating events from Cassandra to PostgreSQL

Start Delta v1.8 with the configuration described in the [configuration section](#migration-configuration). As the
application starts, the Delta log should contain the following lines:

```text
2023-02-08 13:02:26 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting Delta supervisor
2023-02-08 13:02:26 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Delta supervisor is up
2023-02-08 13:02:27 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'migration/migrate-from-cassandra' with strategy 'TransientSingleNode'.
```

### Monitor the health of the platform

Please check the general health of the platform.

### Check the migration progress:

Run the following query on table `migration_progress` in your PostgreSQL instance:

```sql
SELECT name, akka_offset, processed, discarded, failed, instant FROM public.migration_offset;
```

This will return a similar response:

```
   name    |             akka_offset              | processed | discarded | failed |          instant
-----------+--------------------------------------+-----------+-----------+--------+----------------------------
 migration | c64c3630-a3a8-11ed-9b31-b3b1660f61b0 |    267972 |         0 |      0 | 2023-02-03 10:54:39.507+01
```

The table contains the following information:

* `processed`: total number of processed events that have been processed
* `discarded`: total number of events that have been discarded
* `failed`:    number of failures risen during the migration
* `instant`:   timestamp of the last event processed by migration when migration last saved progress

Once the migration terminates, the sum of the processed, discarded, and failed columns should be equal to the number of
events in your Delta 1.7 deployment.

When looking at the logs, these lines should be also repeated (the timestamp should match the current date/hour):

```
2023-02-08 12:56:26 INFO  c.e.b.n.m.replay.ReplayEvents - We got 0 rows
2023-02-08 12:56:26 INFO  c.e.b.n.m.replay.ReplayEvents - Next offset is 1ced2000-a7a8-11ed-8080-808080808080 (2023-02-08 12:00:00:000)
2023-02-08 12:56:26 INFO  c.e.b.n.m.replay.ReplayEvents - No results for current bucket, waiting for 3000 milliseconds
```

Keep looking regularly in the logs to look if the migration is still ongoing without problems. If the migration crashes,
a restart should allow it to start back from where it stopped.

### Post data migration checks

### Internal PostgreSQL consistency check

Once the migration has reached the current date/time, check that the sum of global and scoped events is equal to the
number of processed events. Running the following query, the two columns should be equal:

```sql
SELECT
 (SELECT COUNT(*) FROM scoped_events) +
 (SELECT COUNT(*) FROM global_events) sum_events,
 (SELECT processed FROM migration_offset);
```

### High revision entities check

Find entities that have a high number of revisions:

```sql
SELECT id, max_rev FROM
  (SELECT 
    id, MAX(rev) max_rev 
    FROM scoped_events 
    GROUP BY id
  ) AS idToRev 
 ORDER BY max_rev DESC LIMIT 5;
```

and check that their revision counts match the number of revisions in Cassandra:

```sql
SELECT COUNT(*) FROM delta_1_5.messages WHERE persistence_id = '{persistence_id}' and partition_nr = 0;
```

where the `persistence_id` is of the form `{entity_type}-{org_name}%2F{project_name}_{id}`. Make sure `{id}` has URL
encoded characters.

### Automated migration checks

TODO

## Indexing

Once migration is completed and the previous checks have been performed, Delta can be restarted in normal mode.

* Shut down Delta v1.8 running in migration mode.
* Remove the `MIGRATE_DATA`, `DISABLE_INDEXING` environment variables.
* Restart Delta v1.8, which will now run in normal mode.
* Check the Delta logs after restart. It should contain the following lines:

```text
2023-02-08 13:34:13 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'system/elasticsearch-coordinator' with strategy 'EveryNode'.
2023-02-08 13:34:13 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'system/blazegraph-coordinator' with strategy 'EveryNode'.
2023-02-08 13:34:13 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'system/composite-views-coordinator' with strategy 'EveryNode'.
```

And for each view:

```text
2023-02-08 13:37:09 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'elasticsearch/elasticsearch-{org}/{project}-{viewId}-{revision}' with strategy 'PersistentSingleNode'.
2023-02-08 13:37:09 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'blazegraph/blazegraph-{org}/{project}-{viewId}-{revision}' with strategy 'PersistentSingleNode'.
2023-02-08 13:34:16 INFO  c.e.b.n.d.sourcing.stream.Supervisor - Starting 'compositeviews/composite-views-{org}/{project}-{viewId}-{revision}' with strategy 'TransientSingleNode'.
```

Following these steps, Delta v1.8 will do a complete reindexing of the views that were migrated.

### Notes

* As the entire indexing will take place, some timeouts may occur.
* Leaving kamon disabled (environment variable KAMON_ENABLED set to false) during this indexing is recommended.
* Allocating temporarily more resources to Delta/PostgreSQL/Elasticsearch/Blazegraph may help as this part is greedy in
  resources.
* When indexing is finished, the CPU/memory used by the platform should decrease.

### Post indexing checks

For a given `{org}/{project}` check that the number of indexed resources is correct in the default views.

```sql
WITH vars (myorg, myproj, view_type) AS (
  VALUES ('{org}', '{project}', '{elasticsearch|blazegraph}')
)
SELECT
  (SELECT COUNT(DISTINCT id) FROM scoped_events, vars WHERE org = myorg AND project = myproj) project_resources,
  (SELECT processed-discarded FROM projection_offsets, vars WHERE name LIKE view_type || '-' || myorg || '/' || myproj || '-%default%') indexed_resources;
```

## Clean-up

* Delete all ElasticSearch indices:

```shell
curl -XDELETE 'http://{elasticsearch_host}/delta_*'
```

* Delete BlazeGraph namespaces: TODO:"this should only delete old namespaces"

```shell
for i in `curl -s 'http://{blazegraph_host}/blazegraph/namespace?describe-each-named-graph=false' | grep sparqlEndpoint | grep -o --color "rdf:resource=\"[^\"]*" | sed 's/rdf:resource="//' | sed 's#/sparql$##' | grep -v kb | grep -v LBS`
  do curl -X DELETE "$i"
done
```

* If running Delta v1.8 as a separate instance from Delta v1.7, the latter can be turned off.
* Once Delta v1.8 is up and running and has finished indexing, Cassandra can be turned off.
* Reverse the temporary resources / configuration changes.
    * Remove all `migration` java options
    * Remove all `datastax` java options