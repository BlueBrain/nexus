ship {

  database {
    read = ${ship.database.access}
    # Access to database for write access
    write = ${ship.database.access}
    # Access to database for streaming access (indexing / SSEs)
    streaming = ${ship.database.access}

    # when true it creates the tables on service boot
    tables-autocreate = false

    cache {
      # The max number of tokens in the partition cache
      max-size = 1000
      # The duration after an entry in the cache expires
      expire-after = 10 minutes
    }

    access {
      # the database host
      host = 127.0.0.1
      # the database port
      port = 5432
      # the pool size
      pool-size = 10
    }

    name = "postgres"
    username = "postgres"
    password = "postgres"
  }

  s-3 {
    endpoint = "https://s3.us-east-1.amazonaws.com"

    # the bucket which contains the import files
    import-bucket = "nexus-ship-production"
  }

  input {
    base-uri = "http://localhost:8080/v1"

    event-log {
      query-config = {
        batch-size = 30
        refresh-strategy = 3s
      }
      max-duration = 14 seconds
    }

    view-defaults {
      elasticsearch {
        name = "Default Elasticsearch view"
        description = "An Elasticsearch view of all resources in the project."
      }

      blazegraph {
        name = "Default Sparql view"
        description = "A Sparql view of all resources in the project."
      }
    }

    organizations {
      values {
        # organization example
        #obp = "The Open Brain Platform Organization"
      }
    }

    # Service account configuration for internal operations
    service-account {
      subject: "delta"
      realm: "internal"
    }

    # The bucket to which the files will be copied by the Nexus Ship
    target-bucket = "nexus-delta-production"

    storages {

      # S3 compatible storage configuration
      amazon {
        # to enable s3 storage
        enabled = true
        # the default digest algorithm
        digest-algorithm = "SHA-256"
        # the default endpoint of the current storage
        default-endpoint = "https://s3.us-east-1.amazonaws.com"
        # the access key for the default endpoint
        default-access-key = "my-key"
        # the secret key for the default endpoint
        default-secret-key = "my-secret-key"
        # the default permission required in order to download a file from an S3 storage
        default-read-permission = "resources/read"
        # the default permission required in order to upload a file to a S3 storage
        default-write-permission = "files/write"
        # flag to decide whether or not to show the absolute location of the files in the metadata response
        show-location = true
        # the default maximum allowed file size (in bytes) for uploaded files. 10 GB
        default-max-file-size = 10737418240
      }

      # Disk storage configuration
      disk {
        # the base path where the files are stored
        default-volume = "/tmp"
        # the allowed set of paths where the files are stored
        allowed-volumes = ["/tmp"]
        # algorithm for checksum calculation
        digest-algorithm = "SHA-256"
        # the default permission required in order to download a file from a disk storage
        default-read-permission = "resources/read"
        # the default permission required in order to upload a file to a disk storage
        default-write-permission = "files/write"
        # flag to decide whether or not to show the absolute location of the files in the metadata response
        show-location = false
        # the default maximum allowed file size (in bytes) for uploaded files. 10 GB
        default-max-file-size = 10737418240
      }

      remote-disk {
        # to enable remote storage
        enabled = false
        # the default endpoint
        default-endpoint = "http://localhost:8084/v1"
        # the default credentials for the endpoint
        credentials {
          type: "anonymous"
        }
        # the default digest algorithm
        digest-algorithm = "SHA-256"
        # the default permission required in order to download a file from a remote disk storage
        default-read-permission = "resources/read"
        # the default permission required in order to upload a file to a remote disk storage
        default-write-permission = "files/write"
        # flag to decide whether or not to show the absolute location of the files in the metadata response
        show-location = true
        # the default maximum allowed file size (in bytes) for uploaded files. 10 GB
        default-max-file-size = 10737418240
        # Retry delay for digest computation
        digest-computation-retry-delay = 5s
      }

      # the storages event log configuration
      event-log = ${ship.input.event-log}
      pagination {
        default-size = 30
        size-limit = 1000
        from-limit = 10000
      }

    }
  }
}